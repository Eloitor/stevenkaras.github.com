---
title: Continuous Development
layout: post
---

Extreme programming has generally been regarded as a Good Thing, with many successful companies crediting their ability to deliver projects on time and with superior quality to following the practices outlined by [Extreme Programming](http://en.wikipedia.org/wiki/Extreme_programming).

One of the sadly underdeveloped practices is having a continuous process. The concept that I can have a repeatable build that is constantly being tested and examined is a boon to developers, as it can highlight problematic areas of code, and provide insight into what changes were made that caused the problems. However, most organizations implement this concept of having a continuous process as having a continuous integration server that provides them with nightly builds for some of their projects. If they put forth the effort, they should set up continuous integration to run every time there is a commit in the project, run unit tests every time, and run more expensive functional and acceptance tests at night when the server isn't as busy.

There's something missing here though. The build is run every time there's a commit, not every time there's a change, and once the build starts, it needs to wait until the previous build finished to start. In order for this to be a truly continuous process, it must reuse the results of previous builds and be preemptible. This means that if a new change arrives while it is building, it should stop the current build and start again (hopefully without needing to work twice). This continuous process requires a decoupling of the build and test phases. This allows us to run tests against each completed build, while allowing them to finish each time. It also simplifies the architecture of our continuous development system.

Unfortunately, this style of preemption requires a build system that is dependency aware and is fully aware of when to rebuild its artifacts without including any cruft (leftover files from previous builds that are no longer included in the project). This requires us to use manifests and not glob or pattern match files to include in the build. This level of control over your build process is rare, although it does reflect a mature project that has experienced many changes.

Once we have this preemptible build system, we can focus on improving the testing process. It is reasonable to say that any sufficiently complicated project will have unit tests that take a very long time to run, even though they may cover files or components that aren't changed. At the moment, there have been very few attempts to tie testing into the build process in such a way that it can detect which components were changed and need to be retested. But this approach has several problems. First, not all testing frameworks allow selective running of tests. Second, it requires a level of introspection into build artifacts (and their production) that isn't always available.

While having this sort of continuous process seems a bit excessive for a server that is shared by a team, the real benefit is fully realized when each developer deploys this server to his or her local machine. In this way, they get continuous feedback regarding syntax, compilation errors, and even test status. Their workflow becomes far more focused on developing correct software and helps keep them on task.

This workflow already exists in a few areas, but is not widely known, nor is it available for all frameworks/languages. Notably, web development has gone much more in this direction in recent times, going so far that there are multiple projects that allow forking a local server at different points in the lifecycle. Let's take a look at NodeJS/Grunt and Ruby/Autotest. [Grunt](http://gruntjs.com/) is a component of the Yeoman group of projects whose focus is on Extreme Programming and continuous development. While Grunt does a great job of continuously delivering a built project, it fails in running unit tests automatically and selectively. [Autotest](https://github.com/seattlerb/zentest) for Ruby does a better job of this, yet is generally incapable of selectively running unit tests (though there has been some work in this area).

It's a pity that the build systems available for other languages and frameworks don't yet support this workflow, although I'm certain that by improving the workflow for Ruby/Autotest and similar projects will add momentum and create user demand for such features. Only then can we enter an age of the truly intelligent build, where unit tests are intelligently run against extremely fresh code, and reducing the cost of building a project to a minimum.
